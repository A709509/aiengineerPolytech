{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7109b95e-6adf-438c-93de-7ce9b56e20db",
   "metadata": {},
   "source": [
    "# Use databases and dataviz tools to empower analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137434e-e31f-4f3b-9178-2c5e0ccb701a",
   "metadata": {},
   "source": [
    "In this notebook we will get data from MinIO bucket, insert it into a database table and visualize outputs on an interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e27a0-c9ee-40ab-88ce-3319ca05f746",
   "metadata": {},
   "source": [
    "### 1.1.0 Get data from MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1552a-cc09-4dad-9fa9-7ec27194c17a",
   "metadata": {},
   "source": [
    "With the last notebook, create a minio client, get your parquet file and read it with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f12da9-9ebb-4b6d-959b-594429ba5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependancies\n",
    "from minio import Minio\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO, StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca45073-15fa-4522-bc60-9b6bd7e7033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a client with the access key and the secret key given\n",
    "client = Minio(\n",
    "    \"storage-api.course.aiengineer.sandbox-atos.com\",\n",
    "    access_key=\"tempTP1\",\n",
    "    secret_key=\"tempTP1pw\",\n",
    "    secure=True,\n",
    "    http_client=urllib3.PoolManager(\n",
    "        \n",
    "        retries=urllib3.Retry(\n",
    "            total=5,\n",
    "            backoff_factor=0.2,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0442ae8-ddb1-4627-a661-a476e1bd6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### path to the object into minIO\n",
    "path_minio='datasets/chicago/trips.parquet'\n",
    "\n",
    "### Reuse your bucket name\n",
    "bucket='john-doe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8550550-87a2-4868-a503-18ef19fff38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from minio using get_object, decode it using BytesIO and read the parquet result with pandas\n",
    "try:\n",
    "    response = client.get_object(bucket, path_minio)\n",
    "    # Read data from response.\n",
    "    parquet_object=BytesIO(response.data)\n",
    "    data = pd.read_parquet(parquet_object)\n",
    "finally:\n",
    "    response.close()\n",
    "    response.release_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5451202a-a845-412c-a42b-0b5bbe91934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tips</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>pickup_centroid_latitude</th>\n",
       "      <th>pickup_centroid_longitude</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>extras</th>\n",
       "      <th>trip_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-31T23:45:00.000</td>\n",
       "      <td>746.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.944227</td>\n",
       "      <td>-87.655998</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-31T23:45:00.000</td>\n",
       "      <td>681.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-01-31T23:45:00.000</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>15.20</td>\n",
       "      <td>56.0</td>\n",
       "      <td>41.792592</td>\n",
       "      <td>-87.769615</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-01-31T23:45:00.000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.4</td>\n",
       "      <td>2019-01-31T23:45:00.000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>76.0</td>\n",
       "      <td>41.980264</td>\n",
       "      <td>-87.913625</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tips     trip_start_timestamp  trip_seconds  trip_miles  \\\n",
       "0   0.0  2019-01-31T23:45:00.000         746.0        3.34   \n",
       "1   0.0  2019-01-31T23:45:00.000         681.0        3.00   \n",
       "2  11.0  2019-01-31T23:45:00.000        2280.0       15.20   \n",
       "3   2.0  2019-01-31T23:45:00.000         360.0        1.20   \n",
       "4   8.4  2019-01-31T23:45:00.000        1500.0       11.50   \n",
       "\n",
       "   pickup_community_area  pickup_centroid_latitude  pickup_centroid_longitude  \\\n",
       "0                    6.0                 41.944227                 -87.655998   \n",
       "1                    8.0                 41.899602                 -87.633308   \n",
       "2                   56.0                 41.792592                 -87.769615   \n",
       "3                    8.0                 41.899602                 -87.633308   \n",
       "4                   76.0                 41.980264                 -87.913625   \n",
       "\n",
       "   dropoff_community_area   fare  tolls  extras  trip_total  \n",
       "0                    16.0  11.75    0.0     0.0       11.75  \n",
       "1                    24.0  11.25    0.0     0.0       11.25  \n",
       "2                    22.0  39.00    0.0     5.0       55.00  \n",
       "3                    32.0   6.50    0.0     0.0        8.50  \n",
       "4                     4.0  29.75    0.0     4.0       42.15  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdf0e8-3083-4a81-94da-08df6fc78b05",
   "metadata": {},
   "source": [
    "### 1.1.1 Clickhouse create db and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bcf31",
   "metadata": {},
   "source": [
    "Here we want to store our numerical features for futur analysis / model training / preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "174d547f-d9fa-4da8-9f4e-d89239ca345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import depandancies\n",
    "import pandahouse as ph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558eeb5-b1c8-4755-8497-97b78dce01cc",
   "metadata": {},
   "source": [
    "#### Create clickhouse connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "382957eb-ad02-42ae-8578-5407a910d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The connection dict need a default database\n",
    "connection = dict(database='default',\n",
    "                  host='http://clickhouse-install.clickhouse.svc.cluster.local:8123',\n",
    "                  user='admin',\n",
    "                  password='B1gdata-demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f86f7c58-f3f2-49c7-9cda-8c0d858549e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFORMATION_SCHEMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guillaumedb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>information_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name\n",
       "0  INFORMATION_SCHEMA\n",
       "1             default\n",
       "2         guillaumedb\n",
       "3  information_schema\n",
       "4              system"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph.read_clickhouse('show databases',connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c65811a-cd29-435d-a6f5-0d285cce7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper function for handle this python client\n",
    "def write_clickhouse(query,connection):\n",
    "    print(query)\n",
    "    try:\n",
    "        ph.read_clickhouse(query,connection=connection)\n",
    "    except KeyError:\n",
    "        print(\"Nothing to return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed942c0c-62ec-46d5-9700-dfa3c9db2e55",
   "metadata": {},
   "source": [
    "**Create a db named firstname-lastname, as in your credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b938cfc-e050-42c2-8d84-3636468f4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstname_lastname, as in your credentials but with \"_\" instead of \"-\" because clickhouse does not allow \"-\" in db name\n",
    "dbname = 'john_doe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e796728-4283-459d-bbe7-f6d7151376cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation succeded\n"
     ]
    }
   ],
   "source": [
    "### create a personal database\n",
    "write_clickhouse(f\"create database {dbname}\",connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59eef226-6f96-4316-a0bd-0669adeb7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### override connection dict with personal database\n",
    "connection['database'] = f\"{dbname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f03929-bae3-4c58-9fc4-2d62466976e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'database': 'guillaumedb',\n",
       " 'host': 'http://clickhouse-install.clickhouse.svc.cluster.local:8123',\n",
       " 'user': 'admin',\n",
       " 'password': 'B1gdata-demo'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c465f4-261f-42b7-ab4e-c7385e3881f1",
   "metadata": {},
   "source": [
    "#### Create clickhouse table taxi_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36b0e6-a7aa-42d9-8399-eaf502316901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtable='chicago_taxi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select features\n",
    "features = data[[\n",
    "    \"tips\",\n",
    "    \"trip_start_timestamp\",\n",
    "    \"trip_seconds\",\n",
    "    \"trip_miles\",\n",
    "    \"pickup_community_area\" ,\n",
    "    \"dropoff_community_area\" ,\n",
    "    \"fare\",\n",
    "    \"tolls\",\n",
    "    \"extras\",\n",
    "    \"trip_total\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa315da9-2402-4344-8db6-dbea9bf7e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create table for inserting taxi trip dataset \n",
    "## Clickhouse table definition\n",
    "# using the df informations, and clickhouse documentation write  the create table statement\n",
    "taxitable = f\"\"\"\n",
    "CREATE TABLE {dbname}.{dbtable}\n",
    "(\n",
    "    `tips` Float32,\n",
    "    `trip_start_timestamp` DateTime,\n",
    "    `trip_seconds` Float32,\n",
    "    `trip_miles` Float32,\n",
    "    `pickup_community_area` Float32,\n",
    "    `dropoff_community_area` Float32,\n",
    "    `fare` Float32,\n",
    "    `tolls` Float32,\n",
    "    `extras` Float32,\n",
    "    `trip_total` Float32\n",
    ") \n",
    "ENGINE = MergeTree\n",
    "PARTITION BY toYYYYMM(trip_start_timestamp)\n",
    "ORDER BY trip_start_timestamp;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba0ce0-e7fe-47ed-b47c-45546d508f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_clickhouse(taxitable,connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbfdc9-0b6d-4a63-b054-134c24da69fb",
   "metadata": {},
   "source": [
    "#### Insert the data into taxi_trips table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "832901ae-6889-4078-86c0-7fda7267965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have to be compliant with the clickhouse date type. \n",
    "## we need to force '%Y-%m-%d %H:%M:%S'\n",
    "## force the date format with the defined schema, using pandas\n",
    "features[\"trip_start_timestamp\"] = pd.to_datetime(data[\"trip_start_timestamp\"]).dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cb9a1e9-3cf5-4c98-9869-951a8ea00fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### insert using the to_clickhouse function\n",
    "ph.to_clickhouse(features, dbtable, index=False, chunksize=100000, connection=connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012824ca",
   "metadata": {},
   "source": [
    "### 1.1.2 Postgresql Create db and table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12367a",
   "metadata": {},
   "source": [
    "Here we want to store a referential of pickup community area and related long / lat. To feed future map analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef05f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import depandancies : psycopg2-binary\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the data we create a de-deduplicated, non null value referential\n",
    "scope = data[[\n",
    "    \"pickup_community_area\",\n",
    "    \"pickup_centroid_latitude\",\n",
    "    \"pickup_centroid_longitude\"\n",
    "    ]].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the length of the referential is coherent\n",
    "len(scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head some lines of the scoped data\n",
    "scope.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16fe16",
   "metadata": {},
   "source": [
    "#### Create postgres connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postgres is the default database, autocommit enable folder level actions\n",
    "conn = psycopg2.connect(\n",
    "   database=\"postgres\", user='postgres', password='B1gdata-demo', host='mypostgres.kubegres.svc.cluster.local', port= '5432'\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d546be",
   "metadata": {},
   "source": [
    "#### Create postgres personal DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbaaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the postgres database name\n",
    "# firstname_lastname, as in your credentials but with \"_\" instead of \"-\" because postgres does not allow \"-\" in db name\n",
    "dbname = 'john_doe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the query to create a new database named with the dbname var\n",
    "sqlCreateDb = f\"\"\" create database {dbname}\"\"\"\n",
    "# execute the query using the cursor\n",
    "cursor.execute(sqlCreateDb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4235e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now overwrite the conn with your personnal DB\n",
    "conn = psycopg2.connect(\n",
    "   database=dbname, user='postgres', password='B1gdata-demo', host='mypostgres.kubegres.svc.cluster.local', port= '5432'\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3627934",
   "metadata": {},
   "source": [
    "#### Create table in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set table name\n",
    "table_name='chicago_areas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the right way to define the table using postgresql documentation\n",
    "# focus on schema and types\n",
    "# using the df informations, and postgres documentation write the create table statement\n",
    "\n",
    "areas_table=f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "   pickup_community_area double precision,\n",
    "   pickup_centroid_latitude double precision,\n",
    "   pickup_centroid_longitude double precision )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "## execute the table creation query\n",
    "cursor.execute(areas_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064bddcf",
   "metadata": {},
   "source": [
    "#### Insert data into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fffa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def insert_df_to_table(df,table,conn,cursor):\n",
    "    \"\"\"\n",
    "    insert data to postgres table from pandas dataframe\n",
    "    \"\"\"\n",
    "    # prepare object to stream data\n",
    "    output = StringIO()\n",
    "    # put data into StringIO object as a csv \n",
    "    df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "    # replace output cursor position  position 0\n",
    "    output.seek(0)\n",
    "    # copy content from stream object to table\n",
    "    cursor.copy_from(output, table, null=\"\") # null values become ''\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "insert_df_to_table(scope,table_name,conn,cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c213ed3",
   "metadata": {},
   "source": [
    "#### Verify if content is loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a select statement to get 5 top records of your areas table\n",
    "selectexp = f\" select * from {table_name} limit 5 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a88f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the base and return a Pandas dataframe using read_sql_query function from pandas\n",
    "frame = pd.read_sql_query(selectexp,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663db82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 5 rows you select\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d71045",
   "metadata": {},
   "source": [
    "### 1.1.3 Use kafka brokers and topics to send your data event by event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd02772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependancies\n",
    "# !pip install kafka-python\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7abe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Kafka object called producer, that produce messages to a topic\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[\n",
    "        \"clusterka-kafka-bootstrap.kafka.svc.cluster.local\"\n",
    "        ], \n",
    "        value_serializer= lambda x: x.encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### persist Data locally to allow streaming\n",
    "data.to_csv(\"./chicagodata/to_be_sent_into_kafka.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79474449",
   "metadata": {},
   "source": [
    "#### Create the topic via kafka admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32507cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The topic will be define like your table name\n",
    "topicName = dbname "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependancies\n",
    "from kafka.admin import KafkaAdminClient, NewTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the admin client\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=[\n",
    "        \"clusterka-kafka-bootstrap.kafka.svc.cluster.local\"\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1adc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create an empty list, create a topic with the minimum configuration, add it to the list and call \"create_topic\" with this list\n",
    "topic_list = []\n",
    "topic_list.append(NewTopic(name=topicName, num_partitions=1, replication_factor=1))\n",
    "admin_client.create_topics(new_topics=topic_list, validate_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6946a0a",
   "metadata": {},
   "source": [
    "### Before executing the next cell, open and execute the last notebook : [2_receive_stream_data.ipynb](./2_receive_stream_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78efc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the local file, loop on it and send events with the producer using kafka-python documentation\n",
    "with open(\"./chicagodata/to_be_sent_into_kafka.csv\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i > 0:\n",
    "            producer.send(topic, line)\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41509f2d-1933-4224-b238-6d9ce1e6399d",
   "metadata": {},
   "source": [
    "### 1.1.4 Visualize on superset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96cf398-9ef3-4c54-a5fd-7c85936da60d",
   "metadata": {},
   "source": [
    "Go to [https://dataviz.course.aiengineer.sandbox-atos.com/](https://dataviz.course.aiengineer.sandbox-atos.com/) and log with your account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff58f48-59e1-4f6f-a37d-a8ebeb25457b",
   "metadata": {},
   "source": [
    "on Data > Databases you should see a database named `clickhouse`. This will be our source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e61b74-76e0-488d-9f3d-7e0b46ffa2dc",
   "metadata": {},
   "source": [
    "![source](./images/source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b8105f-e5cc-4626-a305-9e6008685a42",
   "metadata": {},
   "source": [
    "With this source we will create a superset dataset. It maps a table and allow exploration/ chart creation using it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131da8d-9301-4445-9dde-21506b670752",
   "metadata": {},
   "source": [
    "![dataset](./images/dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e2f0c-0d1e-419e-aec3-f965eeef5d3f",
   "metadata": {},
   "source": [
    "![table](./images/table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ce56f-546d-4d52-b595-de4869352a35",
   "metadata": {},
   "source": [
    "One you choose the dataset, click on it and start create some charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2c2d1-bc83-4fce-bfe3-7dd1f1c2b0b1",
   "metadata": {},
   "source": [
    "![tips](./images/tips.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a058d-abeb-444e-a539-f9bd28223c16",
   "metadata": {},
   "source": [
    "**In this example**\n",
    "\n",
    "- Chart type is bar chart\n",
    "- No time range because dataset has old dates values\n",
    "- metric is average tips (y)\n",
    "- serie is pickup location (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b37c06-a0a0-42b9-a2c2-c4602ad2d36e",
   "metadata": {},
   "source": [
    "You can name, save and assign chart to a dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb54d62-024c-41ce-967f-85aba9f4c39e",
   "metadata": {},
   "source": [
    "**Go further : Create a dashboard with multiple vizualisation answering to feature analysis, try to represent the dataset on a map**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1db6d0c0fb62fcd92812f526c45c77dc568410c92bb0ad7cc615a53ad33175c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
